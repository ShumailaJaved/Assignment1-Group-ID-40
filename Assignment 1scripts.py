# -*- coding: utf-8 -*-
"""24280078,24280014 Project Data Mosaic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CDS5FZ92HYihPm9xz8ckwLwUlUF_vCL2

## <span style="color:red">**Source 1: Cricket Posts from Reddit**</span>
"""

!pip install praw
import praw
import csv

reddit_read_only = praw.Reddit(client_id="iUBp_cPhAswqbfRU8Ru0BQ",         # your client id
                               client_secret="DSNwG0M1mnHdpQ4yCGSsYLcOJl4b7w",      # your client secret
                               user_agent="DEScraping")        # your user agent

subreddit = reddit_read_only.subreddit("cricket")

for post in subreddit.hot(limit=10):
    print(post.title)

posts = subreddit.hot()


posts_dict = {"ID":[], "Title": [], "Text": [],
              "Author": [], "Date": [],
              "Upvotes": [], "Subreddit Name": []
              }

for post in posts:
    posts_dict["ID"].append(post.id)
    posts_dict["Title"].append(post.title)
    posts_dict["Text"].append(post.selftext)
    posts_dict["Author"].append(post.author)
    posts_dict["Date"].append(post.created_utc)
    posts_dict["Upvotes"].append(post.score)
    posts_dict["Subreddit Name"].append(post.name)

posts_list = [
    {k: v[i] for k, v in posts_dict.items()}
    for i in range(len(posts_dict['ID']))
]


with open('RedditPosts.csv', 'w', newline='', encoding="utf-8") as csvfile:
    fieldnames = ('ID', 'Title', 'Text', 'Author', 'Date', 'Upvotes','Subreddit Name')
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(posts_list)


csvfile.close()

!pip install wordcloud
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

text = ""
with open('RedditPosts.csv', 'r', encoding="utf-8") as file:
    reader = csv.DictReader(file)
    for row in reader:
        text += row['Title'] + " "

stopwords = set(STOPWORDS)
stopwords.update(["said", "would", "could", "one", 'cricket', 'reddit','https','thread','vs','Match','ODI'])


wordcloud = WordCloud(width=1000, height=600,
                      background_color='white',
                      stopwords=stopwords,
                      min_font_size=10).generate(text)

plt.figure(figsize=(8, 8), facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad=0)
plt.show()

"""## <span style="color:red">**Source 2: Stocks Closing Price for top Cricket Sponsors from Yahoo Finance**</span>

"""

!pip install yfinance
import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

tickers = ['CCOLA.IS', 'PEP', '2223.SR']
historical_data = pd.DataFrame()

for etf in tickers:
  ticker = yf.Ticker(etf)
  temp_df = ticker.history(period="2y")
  temp_df['ETF'] = etf
  historical_data = pd.concat([historical_data, temp_df ])



Stock_Close = historical_data[['ETF','Close']].copy()
Stock_Close.sort_values(by='Date', ascending=True, inplace=True)
Stock_Close.head(10)

Stock_Close.groupby('ETF')['Close'].describe().transpose()

Stock_Close = Stock_Close.reset_index()

pivot_data = Stock_Close.pivot(index='Date', columns='ETF', values='Close')

plt.figure(figsize=(15, 6))
sns.lineplot(data=pivot_data, linestyle = '-')

plt.title('Time Series of Closing Prices for ETFs')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.legend(title='ETFs')
plt.grid(True)

plt.show()

Stock_Close = Stock_Close.reset_index(drop=True)

pivot_data = Stock_Close.pivot(index='Date', columns='ETF', values='Close')

plt.figure(figsize=(10, 6))
sns.violinplot(x='ETF', y='Close', data=historical_data, hue='ETF')
plt.title('Distribution of Closing Prices for ETFs')
plt.xlabel('ETF')
plt.ylabel('Closing Price')
plt.show()

"""## <span style="color:red">**Source 3: Dataset from Kaggle**</span>"""

!pip install kaggle

!mkdir -p ~/.kaggle

from google.colab import files
files.upload()

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d utkarshtomar736/odi-mens-cricket-match-data-2002-2023

!unzip -q odi-mens-cricket-match-data-2002-2023.zip

df = pd.read_csv('ODI_Match_info.csv')
df.head()

df.shape

df.info()

df.describe()

print(df.isnull().sum())


print(df.isnull().sum().sum())

df_cleaned = df.drop(columns=['id'])


print("Original dataset shape:", df.shape)


print("Shape after dropping columns:", df_cleaned.shape)


df_cleaned = df_cleaned.dropna().reset_index(drop=True)


print("Shape after dropping missing rows:", df_cleaned.shape)

import matplotlib.pyplot as plt


stats = df[['win_by_runs', 'win_by_wickets']].describe()


fig, axes = plt.subplots(2, 2, figsize=(6, 5))


axes[0, 0].bar(stats.columns, stats.loc['count'])
axes[0, 0].set_title('Count')


axes[0, 1].bar(stats.columns, stats.loc['mean'])
axes[0, 1].set_title('Mean')


axes[1, 0].bar(stats.columns, stats.loc['min'])
axes[1, 0].set_title('Min')


axes[1, 1].bar(stats.columns, stats.loc['max'])
axes[1, 1].set_title('Max')

plt.tight_layout()
plt.show()